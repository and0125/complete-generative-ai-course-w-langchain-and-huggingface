# Notes

Course covers:

- python programming from basic to advanced
- NLP as used in deep learning: covers NLP which is necessary for deep learning, RNN, LSTM RNN, GRU RNN, every RNN we'll understand intutions and why the next version of the RNN was created. This will be useful for any NLP use cases. There's also Bidirectional RNN; then we'll understand encoder and decoders, which will focus on basic things. Also study attention mechanism, and also study transformers, and BeRT. Once we complete all these topics, we'll have a basic understanding to understanding LLM models which are generative AI models and to obtain an understanding of what this means.
- Langchain: this is one of the most popular generative AI frameworks which will help you develop amazing Gen AI applications. This will enable you to use Paid LLMs, multimodal LLMs, and Open Source LLMs. This is helpful for working with agents as well, creating applications like Chatting with a database, etc. The main aim is to understand the features of langchain like vector databases, retrievals, creating chains, how to do text summarization, how to create chat bots to work with the chat message history. There will be a lot of functionality they'll break down.
  - 3 important libraries - langchain, langchain core, and langchain community modules. and we'll talk about the functionalities that are specific to each. Many more important modules to use in this eco-system. This will enable you to create amazing LLM projects, which will help you handle real world use case scenarios.
- Then we'll get to understand the deployment techniques to use, and will cover free resources that are available. We won't cover any paid services for deployment.

We will use streamlit to develop these entire applications. Another package for this is gradio.

After covering deployment techniques, we need to learn about fine-tuning techniques, which we'll use google Colab for; we'll use its free resources for this.

One paid model we'll use is OpenAI, which is one LLM we'll learn.

Then we'll learn the important techniques for Colab like quantization, LoRA, CoRA, and then we'll learn how to fine tune open source LLM models.

- Working with Gen AI and AWS: AWS bedrock - has many open source models, and Lambda functions, API gateway, and this would be for end to end projects. Then we can deploy this completely within AWS sagemaker. This would be another module we can work with.

- NVIDIA NIM: this is becoming a very popular model. Its for deploying a generative AI model in the cloud, and you can see what open source models are available in this platform too. This also uses langchain.

- CREW AI: helps to create multi-AI agents, which helps to solve different Gen AI applications. Will also use AWS, this has its own framework, like langchain but not langchain. This should help you to crack jobs and open a startup for Generative AI.

## Models Used

- Paid and open source LLMs:
  - OpenAI -- using GPT 4.0 GPT 4 Turbo; Open AI embedding techniques
  - Google Gemma 2 model
  - Meta Llama3
  - Mistral from Anthropic
- Hugging Face
  - lots of LLM models used on this platform.

This will help create generative AI applications.

Will also use Groq AI infrastructure for deploying these models; Groq is an LPU engine, which is better than a GPU for these models.


